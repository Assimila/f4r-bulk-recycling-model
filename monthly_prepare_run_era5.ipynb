{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5480d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sys \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time as timer\n",
    "start_all = timer.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3810b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf =\"/Volumes/ESA_F4R/era/\" \n",
    "datao =\"/Volumes/ESA_F4R/ed_prepare/\" \n",
    "#datao =\"/Users/ellendyer/Library/Mobile Documents/com~apple~CloudDocs/1SHARED_WORK/Work/3_ESA_GRANT/MODEL/data/era/\" \n",
    "datap =\"/Users/ellendyer/Library/Mobile Documents/com~apple~CloudDocs/1SHARED_WORK/Work/3_ESA_GRANT/MODEL/plots/era/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb79a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For selection and plotting\n",
    "Y1, Y2 = 1995,1995\n",
    "#m1 = '03'\n",
    "time_bnds = (str(Y1)+'-01-01',str(Y2)+'-12-31')\n",
    "lon_bnds, lat_bnds = (15, 30), (5,-10)\n",
    "#p_bnds = (1000,300) #for daily folder files\n",
    "p_bnds = (30000,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a9238c",
   "metadata": {},
   "source": [
    "Read in ERA5 data on pressure levels (hourly in fortnightly files)\n",
    "- resampled to monthly MS timestep\n",
    "- shum multiplied by 1000 to convert from kg/kg --> g/kg\n",
    "- pressure levels are divided by 100 to convert from Pa to hPa (only for fortnightly files)\n",
    "- sort data by descending pressure levels (only for fortnightly files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf063f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer.time()\n",
    "from functools import partial\n",
    "def _preprocess_pres(x, lon_bnds, lat_bnds, p_bnds):\n",
    "    return x.sel(lon=slice(*lon_bnds), lat=slice(*lat_bnds),\n",
    "                 plev=slice(*p_bnds),drop=True)\n",
    "partial_func_pres = partial(_preprocess_pres, lon_bnds=lon_bnds, lat_bnds=lat_bnds, p_bnds=p_bnds)\n",
    "\n",
    "#Reading in pressure level variables from ERA5\n",
    "ds_era_pres = xr.open_mfdataset(dataf+\"era5/pressure_levels/era5_pressure_level_variables_central_africa_\"+str(Y1)+\"*.nc\",\n",
    "                                drop_variables=['r','t','w'],\n",
    "                                preprocess=partial_func_pres,parallel=True).resample(time='MS').mean(dim='time').load()\n",
    "ds_era_pres = ds_era_pres.sel(time=slice(*time_bnds),drop=True)\n",
    "ds_era_pres = ds_era_pres.rename({'plev':'level','q':'Shum','u':'Uwnd','v':'Vwnd'})\n",
    "ds_era_pres['Shum'] = 1000.0*ds_era_pres['Shum']\n",
    "ds_era_pres['level'] = ds_era_pres['level']/100.0 #for half monthly files only \n",
    "ds_era_pres = ds_era_pres.sortby('level', ascending=False) #for half monthly files only\n",
    "end = timer.time()\n",
    "length = end - start\n",
    "print(\"ERA5 pressure level data read in took \", length, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875607f",
   "metadata": {},
   "source": [
    "Read in ERA5 land data (hourly in monthly files)\n",
    "- resampling to daily first because evap and prec need to be summed rather than averaged at the daily scale (mm/day) while surface pressure is averaged\n",
    "- prec is multiplied by 1000 to convert from m to mm\n",
    "- evap is multiplied by -1000 to convert from m to mm and upward fluxes in land model are considered negative\n",
    "- then resampled to MS monthly and also interpolated to coarser pressure level grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer.time()\n",
    "from functools import partial\n",
    "def _preprocess_land(x, lon_bnds, lat_bnds):\n",
    "    x = x.sel(longitude=slice(*lon_bnds), latitude=slice(*lat_bnds),drop=True)\n",
    "    return x\n",
    "partial_func_land = partial(_preprocess_land, lon_bnds=lon_bnds, lat_bnds=lat_bnds)\n",
    "\n",
    "#Reading in surface variables from ERA5 Land\n",
    "ds_era_land = xr.open_mfdataset(\"/Volumes/ESA_F4R/era/era5_land/era5_land_variables_central_africa_\"+str(Y1)+\"*.nc\",\n",
    "                                drop_variables=['expver','number','pev','ssr','t2m'],\n",
    "                                preprocess=partial_func_land,parallel=True).load()\n",
    "ds_era_land = ds_era_land.sel(valid_time=slice(*time_bnds),drop=True)\n",
    "ds_era_land = ds_era_land.rename({'valid_time':'time','latitude':'lat',\n",
    "                                  'longitude':'lon','tp':'Prec','e':'Evap','sp':'Psfc'})\n",
    "ds_era_land = ds_era_land.interp(lat=ds_era_pres['lat'],lon=ds_era_pres['lon'],method='linear',kwargs={\"fill_value\": \"extrapolate\"})\n",
    "#print('era after int before resample',ds_era_land)\n",
    "Psfc = ds_era_land['Psfc'].resample(time='D').mean(dim='time')/100.0\n",
    "ds_era_land = ds_era_land.resample(time='D').sum(dim='time')\n",
    "ds_era_land['Psfc'] = Psfc\n",
    "ds_era_land['Prec'] = ds_era_land['Prec']*1000.0 \n",
    "ds_era_land['Evap'] = ds_era_land['Evap']*-1000.0 \n",
    "ds_era_land = ds_era_land.resample(time='MS').mean(dim='time')\n",
    "end = timer.time()\n",
    "length = end - start\n",
    "print(\"ERA5 land data read in took \", length, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f41793",
   "metadata": {},
   "source": [
    "Merging the two datasets into one dataset for recyling code called ds\n",
    "- close both input datasets\n",
    "- sort everything so latitude is south to north\n",
    "- transpose dimensions so they run (lon,lat,level,time) as in recycling code\n",
    "- save input ds to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer.time()\n",
    "ds = xr.merge([ds_era_pres,ds_era_land]) \n",
    "ds_era_pres.close()\n",
    "ds_era_land.close()\n",
    "ds = ds.sortby('lat', ascending=True)\n",
    "ds = ds.transpose(\"lon\", \"lat\", \"level\", \"time\",missing_dims='ignore')\n",
    "ds.to_netcdf(datao+\"erads_\"+str(Y1)+\".nc\", mode='w', format='NETCDF4', engine='netcdf4')\n",
    "end = timer.time()\n",
    "length = end - start\n",
    "print(\"Merging and dataset output took \", length, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepping datasets near surface for recycling\n",
    "import bulk_recycling_model.numerical_integration\n",
    "\n",
    "# Integrate 10^-3 Shum Uwnd dp\n",
    "# Because the integration limits are from high pressure to low pressure, we need to invert the sign.\n",
    "integrand = -1 * 1e-3 * ds[\"Shum\"] * ds[\"Uwnd\"]\n",
    "Fx = bulk_recycling_model.numerical_integration.integrate_no_extrapolation(integrand, ds[\"Psfc\"])\n",
    "# Units: mb x m/s\n",
    "\n",
    "# Integrate 10^-3 Shum Vwnd dp\n",
    "# Because the integration limits are from high pressure to low pressure, we need to invert the sign.\n",
    "integrand = -1 * 1e-3 * ds[\"Shum\"] * ds[\"Vwnd\"]\n",
    "Fy = bulk_recycling_model.numerical_integration.integrate_no_extrapolation(integrand, ds[\"Psfc\"])\n",
    "# Units: mb x m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and scale the data\n",
    "\n",
    "# %%\n",
    "from bulk_recycling_model import preprocess\n",
    "from bulk_recycling_model.axis import Axis\n",
    "from bulk_recycling_model.scaling import Scaling, UnitSystem\n",
    "\n",
    "print(\"prepping data for recycling - scaling and flux calcs etc\")\n",
    "\n",
    "# %%\n",
    "# degrees\n",
    "L = ds.coords[\"lon\"].max().item() - ds.coords[\"lon\"].min().item()\n",
    "# convert to meters\n",
    "L = L * 111e3 * np.cos(np.deg2rad(ds.coords[\"lat\"].mean().item()))\n",
    "dx = L / ds.sizes[\"lon\"]\n",
    "\n",
    "# %%\n",
    "# lon axis\n",
    "lon_axis = Axis(\n",
    "    ds.coords[\"lon\"].min().item(),\n",
    "    ds.coords[\"lon\"].diff(\"lon\").mean().item(),\n",
    "    ds.sizes[\"lon\"],\n",
    ")\n",
    "\n",
    "# %%\n",
    "# degrees\n",
    "H = ds.coords[\"lat\"].values[-1] - ds.coords[\"lat\"].values[0]\n",
    "# convert to meters\n",
    "H = H * 111e3\n",
    "dy = H / ds.sizes[\"lat\"]\n",
    "\n",
    "# %%\n",
    "# lat axis\n",
    "lat_axis = Axis(\n",
    "    ds.coords[\"lat\"].min().item(),\n",
    "    ds.coords[\"lat\"].diff(\"lat\").mean().item(),\n",
    "    ds.sizes[\"lat\"],\n",
    ")\n",
    "\n",
    "# %%\n",
    "print(f\"{L = :.2e} m\")\n",
    "print(f\"{dx = :.2e} m\")\n",
    "print(f\"{H = :.2e} m\")\n",
    "print(f\"{dy = :.2e} m\")\n",
    "\n",
    "# %%\n",
    "# make a scaling object to convert between unit systems\n",
    "scaling = Scaling(H)\n",
    "\n",
    "# %%\n",
    "dx = scaling.distance.convert(dx, UnitSystem.SI, UnitSystem.scaled)\n",
    "dy = scaling.distance.convert(dy, UnitSystem.SI, UnitSystem.scaled)\n",
    "print(f\"{dx = :.2e} scaled\")\n",
    "print(f\"{dy = :.2e} scaled\")\n",
    "\n",
    "# %%\n",
    "# convert Fx and Fy to scaled units\n",
    "Fx = scaling.water_vapor_flux.convert(Fx.values, UnitSystem.natural, UnitSystem.scaled)\n",
    "Fy = scaling.water_vapor_flux.convert(Fy.values, UnitSystem.natural, UnitSystem.scaled)\n",
    "\n",
    "# %%\n",
    "# convert E to scaled units\n",
    "#print('pre-scaled',ds['Evap'])\n",
    "E = scaling.evaporation.convert(ds[\"Evap\"].values, UnitSystem.natural, UnitSystem.scaled)\n",
    "#print('scaled',E)\n",
    "#print('Fx',Fx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b5fe82",
   "metadata": {},
   "source": [
    "- Create recycling output array based on the shape of one of the surface input files: evap (E)\n",
    "- Run through each timestep in the input files and calculate recycling ratio at each timestep across domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_ar = np.empty((np.shape(E)[0]-1,np.shape(E)[1]-1,np.shape(E)[2]))\n",
    "# Entering preprocessing and time step loop\n",
    "#print(\"run model and plot\")\n",
    "for i,time in enumerate(ds.time):\n",
    "     \n",
    "    # %%\n",
    "    # preprocess E onto the secondary grid\n",
    "    Ei = preprocess.prepare_E(E[:,:,i])\n",
    "    \n",
    "    # %%\n",
    "    # preprocess water vapor fluxes onto the secondary grid\n",
    "    Fxi_left = preprocess.prepare_Fx_left(Fx[:,:,i])\n",
    "    Fxi_right = preprocess.prepare_Fx_right(Fx[:,:,i])\n",
    "    Fyi_bottom = preprocess.prepare_Fy_bottom(Fy[:,:,i])\n",
    "    Fyi_top = preprocess.prepare_Fy_top(Fy[:,:,i])\n",
    "    #print(Fxi_left)\n",
    "    #print(Fxi_right)\n",
    "    \n",
    "    # %%\n",
    "    # compute P\n",
    "    Pi = preprocess.calculate_precipitation(Fxi_left, Fxi_right, Fyi_bottom, Fyi_top, Ei, dx, dy)\n",
    "    \n",
    "    # Run the model\n",
    "    \n",
    "    # %%\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # %%\n",
    "    import logging\n",
    "    \n",
    "    logging.basicConfig()\n",
    "    logging.getLogger(\"bulk_recycling_model\").setLevel(logging.INFO)\n",
    "    \n",
    "    # %%\n",
    "    from bulk_recycling_model import plotting\n",
    "    #from bulk_recycling_model.main_ncltest import run\n",
    "    from bulk_recycling_model.main import run\n",
    "    \n",
    "    # %%\n",
    "    class Callback:\n",
    "        def __init__(self):\n",
    "            self.n_calls = 0  # number of times callback has executed\n",
    "    \n",
    "        def __call__(self, rho: np.ndarray, k: int):\n",
    "            fig, ax = plt.subplots()\n",
    "            collection = plotting.pcolormesh(ax, rho, lon_axis, lat_axis, vmin=0.0, vmax=0.8)\n",
    "            fig.colorbar(collection)\n",
    "            fig.suptitle(f\"$\\\\rho^k$ @ k={k:04d}\")\n",
    "            plt.savefig(datap+\"{self.n_calls:05d}_{k:04d}.png\")\n",
    "            plt.close(fig)\n",
    "            self.n_calls += 1\n",
    "    \n",
    "    # %%\n",
    "    #! rm plots/*.png\n",
    "    \n",
    "    # %%\n",
    "    status = run(\n",
    "        Fxi_left,\n",
    "        Fxi_right,\n",
    "        Fyi_bottom,\n",
    "        Fyi_top,\n",
    "        Ei,\n",
    "        Pi,\n",
    "        dx,\n",
    "        dy,\n",
    "        max_iter=500,\n",
    "        tol=1e-3,\n",
    "        #callback=Callback(),\n",
    "    )\n",
    "#Section of code to test what is happening when convergence fails\n",
    "#Plots convergence over iterations\n",
    "#    if status[\"success\"]==False:\n",
    "#        print(\"Failed convergence\")\n",
    "#        print(i,time.values)\n",
    "#        print(\"failed rho: \",status[\"rho\"])\n",
    "#        deltas = status[\"deltas\"]\n",
    "#        fig, ax = plt.subplots()\n",
    "#        ax.plot(deltas)\n",
    "#        ax.set_title(\"Convergence\")\n",
    "#        ax.set_xlabel(\"Iteration\")\n",
    "#        plt.show()\n",
    "#        plt.close()\n",
    "\n",
    "#Print timestep and status (converged or not) and add rho to recycling ration array\n",
    "    print(i,time.values)\n",
    "    print(status['k'])\n",
    "    rho_ar[:,:,i] = status[\"rho\"]\n",
    "\n",
    "    # %%\n",
    "    # plot each timestep \n",
    "    fig, ax = plt.subplots()\n",
    "    collection = plotting.pcolormesh(ax, status[\"rho\"], lon_axis, lat_axis)\n",
    "                                     #vmin=0.0, vmax=0.8)\n",
    "    fig.colorbar(collection)\n",
    "    fig.suptitle(str(time.values)+\" $\\\\rho$\")\n",
    "    plt.savefig(datap+\"rho_\"+str(time.values)+\".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    # %%\n",
    "    # plot the convergence\n",
    "    deltas = status[\"deltas\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(deltas)\n",
    "    ax.set_title(\"Convergence\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691447a",
   "metadata": {},
   "source": [
    "- Create an xarray to store all of the calculated recycling ratios that is organised in an easy to plot/interpret format\n",
    "- Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_ar = np.linspace(start=ds.coords[\"lon\"].min().values+lon_axis.step/2,\n",
    "                     stop=ds.coords[\"lon\"].max().values-lon_axis.step/2,\n",
    "                     num=lon_axis.n_points-1)\n",
    "lat_ar = np.linspace(start=ds.coords[\"lat\"].min().values+lat_axis.step/2,\n",
    "                     stop=ds.coords[\"lat\"].max().values-lat_axis.step/2,\n",
    "                     num=lat_axis.n_points-1)\n",
    "rho_xarr = xr.DataArray(\n",
    "    data=rho_ar,\n",
    "    dims=[\"lon\", \"lat\", \"time\"],\n",
    "    coords=dict(\n",
    "        lon=([\"lon\"], lon_ar),\n",
    "        lat=([\"lat\"], lat_ar),\n",
    "        time=([\"time\"],ds.time.data)\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"Recycling ratio\",\n",
    "        units=\"%\",\n",
    "    ),\n",
    ") \n",
    "rho_xarr = rho_xarr.transpose(\"time\",\"lat\",\"lon\")\n",
    "rho_xarr.to_netcdf(datao+\"rho_era5_\"+str(Y1)+\".nc\")\n",
    "print('Number of rhos over 1: ', rho_xarr.where(rho_xarr.values>1.0).count().values)\n",
    "\n",
    "end_all = timer.time()\n",
    "length = end_all - start_all\n",
    "print(\"Running the whole prep and recycling code took \", length, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba25ba",
   "metadata": {},
   "source": [
    "Create seasonal arrays and plot these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79973fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mam_rho = rho_xarr.sel(time=rho_xarr.time.dt.month.isin([3,4,5]))\n",
    "fig, ax = plt.subplots()\n",
    "#collection = mam_rho.mean(\"time\").plot.contourf(vmin=0.0,vmax=0.75,levels=12,ax=ax)\n",
    "collection = mam_rho.mean(\"time\").plot.contourf(levels=12,ax=ax)\n",
    "fig.suptitle(\"MAM $\\\\rho$\")\n",
    "plt.savefig(datao+\"rho_MAM_\"+str(Y1)+\".png\")\n",
    "plt.show()\n",
    "    \n",
    "#son_rho = rho_xarr.sel(time=rho_xarr.time.dt.month.isin([9,10,11]))\n",
    "#print(son_rho)    \n",
    "#fig, ax = plt.subplots()\n",
    "#collection = son_rho.mean(\"time\").plot.contourf(vmin=0.0,vmax=0.75,levels=12,ax=ax)\n",
    "#fig.suptitle(\"SON $\\\\rho$\")\n",
    "##plt.savefig(datap+\"rho_SON\"+str(year1)+\"_\"+str(year2)+\".png\")\n",
    "#plt.show()\n",
    "#\n",
    "#jja_rho = rho_xarr.sel(time=rho_xarr.time.dt.month.isin([6,7,8]))\n",
    "#print(jja_rho)    \n",
    "#fig, ax = plt.subplots()\n",
    "#collection = jja_rho.mean(\"time\").plot.contourf(vmin=0.0,vmax=0.75,levels=12,ax=ax)\n",
    "#fig.suptitle(\"JJA $\\\\rho$\")\n",
    "##plt.savefig(datap+\"rho_JJA\"+str(year1)+\"_\"+str(year2)+\".png\")\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f4r-bulk-recycling-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
